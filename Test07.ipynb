{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944f6f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca547d",
   "metadata": {},
   "source": [
    "### 加载词向量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c964a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4762"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pickle as pkl\n",
    "vocab = pkl.load(open('./rnn_data/vocab.pkl','rb'))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b010d3",
   "metadata": {},
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bddb3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180000it [00:01, 142112.75it/s]\n",
      "10000it [00:00, 120334.41it/s]\n",
      "10000it [00:00, 156114.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def load_dataset(path, pad_size=32):\n",
    "    contents = []\n",
    "    with open(path, 'r', encoding='UTF-8') as f:\n",
    "        for line in tqdm(f):\n",
    "            lin = line.strip()\n",
    "            if not lin:\n",
    "                continue\n",
    "            content, label = lin.split('\\t')\n",
    "            words_line = []\n",
    "            token = [x for x in content]\n",
    "            seq_len = len(token)\n",
    "            if pad_size:\n",
    "                if len(token) < pad_size:\n",
    "                    token.extend([vocab.get('<PAD>')] * (pad_size - len(token)))\n",
    "                else:\n",
    "                    token = token[:pad_size]\n",
    "                    seq_len = pad_size\n",
    "            # word to id\n",
    "            for word in token:\n",
    "                words_line.append(vocab.get(word, vocab.get('<UNK>')))\n",
    "            contents.append((words_line, int(label), seq_len))\n",
    "    return contents  # [([...], 0), ([...], 1), ...]\n",
    "\n",
    "\n",
    "train_ds = load_dataset('./rnn_data/train.txt')\n",
    "dev_ds = load_dataset('./rnn_data/dev.txt')\n",
    "test_ds = load_dataset('./rnn_data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137b8ae",
   "metadata": {},
   "source": [
    "### 数据集迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b4e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterater(object):\n",
    "    def __init__(self, batches, batch_size, device):\n",
    "        self.batches = batches\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = len(batches) // batch_size\n",
    "        self.residue = (len(batches) % batch_size == 0)\n",
    "        \n",
    "        self.index = 0\n",
    "        self.device = device\n",
    "        \n",
    "    def _to_tensor(self, datas):\n",
    "        x = torch.LongTensor([_[0] for _ in datas]).to(self.device)\n",
    "        y = torch.LongTensor([_[1] for _ in datas]).to(self.device)\n",
    "        seq_len = torch.LongTensor([len(_[0]) for _ in datas]).to(self.device)\n",
    "        \n",
    "        return (x, seq_len),y\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.residue and self.index == self.n_batches:\n",
    "            batches = self.batches[self.index*self.batch_size : len(self.batches)]\n",
    "            self.index += 1\n",
    "            batches = self._to_tensor(batches)\n",
    "            return batches\n",
    "        \n",
    "        if self.index > self.n_batches:\n",
    "            self.index = 0\n",
    "            raise StopIteration\n",
    "            pass\n",
    "        else:\n",
    "            batches = self.batches[self.index*self.batch_size: (self.index+1)*self.batch_size]\n",
    "            batches = self._to_tensor(batches)\n",
    "            self.index += 1\n",
    "#             print('n',batches)\n",
    "            return batches\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_batches + (1 if self.residue else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18beffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bee16af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DatasetIterater(train_ds, 128, device)\n",
    "dev_dl = DatasetIterater(dev_ds, 128, device)\n",
    "test_dl = DatasetIterater(test_ds, 128, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ed505",
   "metadata": {},
   "source": [
    "### 加载已训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d4a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeding_pretrained = torch.tensor(\n",
    "    np.load('./rnn_data/embedding_Tencent.npz')['embeddings'].astype('float32')\n",
    ")\n",
    "embeding_pretrained.shape\n",
    "class_list = [x.strip() for x in open(\n",
    "        './rnn_data/class.txt'\n",
    "    ).readlines()]\n",
    "class_list\n",
    "num_classes = len(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95148bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4762, 200])\n"
     ]
    }
   ],
   "source": [
    "print(embeding_pretrained.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59de794",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3628007",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embd_pretrained, classes_num):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embd_pretrained, freeze=False)\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, 256, (k, embd_pretrained.size(1))) for k in (2,3,4)]\n",
    "            #          (input channels, output_channels, kerner_size\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(256*3, classes_num)\n",
    "        \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = conv(x)   # [batch_size 1, 32, vocab_size] -> [batch_size, 256, 31/30/29, 1]\n",
    "        x = F.relu(x).squeeze(3)  # [batch_size, 256, 31/29/28]\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)  # [batch_size, 256]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x[1] = seq_len\n",
    "        out = self.embedding(x[0]) # [batch_size , 32 , vocab_size]\n",
    "        out = out.unsqueeze(1)   # [batche_size , 1, 32, vocab_size]\n",
    "        out = [self.conv_and_pool(out, conv) for conv in self.convs]\n",
    "        out = torch.cat(out, 1)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c336c",
   "metadata": {},
   "source": [
    "### 训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18598ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train(model, train_dl, dev_dl,epoches, writer = None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    total_batch = 0\n",
    "    for epoch in (range(epoches)):\n",
    "        print('{}/{}'.format(epoch, epoches))\n",
    "        \n",
    "        for x, labels in train_dl:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()  # TODO ???\n",
    "            outputs = model(x)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if total_batch % 100 == 0:\n",
    "                true = labels.data.cpu()\n",
    "                predict = torch.max(outputs.data, 1)[1].cpu()\n",
    "#                 print(true)\n",
    "#                 print(predict)\n",
    "                train_acc = metrics.accuracy_score(true, predict)\n",
    "                print('train_acc = {:.4f}'.format(train_acc))\n",
    "                dev_acc, dev_loss = evalute(model, dev_dl )\n",
    "                print('dev_acc = {:.4f}, dev_loss={:.4f}'.format(dev_acc, dev_loss))\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar('loss/train', loss.item(), total_batch)\n",
    "                    writer.add_scalar('loss/dev', dev_loss, total_batch)\n",
    "                    writer.add_scalar('acc/train', train_acc, total_batch)\n",
    "                    writer.add_scalar('acc/dev', dev_acc, total_batch)\n",
    "                \n",
    "            total_batch += 1\n",
    "\n",
    "import numpy as np\n",
    "def evalute(model, data_dl, test=False):\n",
    "    model.eval()\n",
    "    loss_total = 0\n",
    "    predict_all = np.array([], dtype = int)\n",
    "    labels_all = np.array([], dtype=int)\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in data_dl:\n",
    "            outputs = model(texts)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss_total += loss\n",
    "            labels = labels.data.cpu()\n",
    "            predict = torch.max(outputs.data.cpu(), 1)[1].cpu().numpy()\n",
    "            labels_all = np.append(labels_all, labels)\n",
    "            predict_all = np.append(predict_all, predict)\n",
    "            \n",
    "        acc = metrics.accuracy_score(labels_all, predict_all)\n",
    "        \n",
    "    return acc, loss_total / len(data_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e3a8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_txtcnn = TextCNN(embeding_pretrained, len(class_list))\n",
    "model_txtcnn = model_txtcnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e34407c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "writer = SummaryWriter(log_dir='./log/' + time.strftime('%m-%d_%H.%M', time.localtime()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d255daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10\n",
      "train_acc = 0.9062\n",
      "dev_acc = 0.9010, dev_loss=0.3243\n",
      "train_acc = 0.8906\n",
      "dev_acc = 0.9034, dev_loss=0.3345\n",
      "train_acc = 0.8984\n",
      "dev_acc = 0.8986, dev_loss=0.3416\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9033, dev_loss=0.3355\n",
      "train_acc = 0.8594\n",
      "dev_acc = 0.9052, dev_loss=0.3324\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9044, dev_loss=0.3316\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9053, dev_loss=0.3304\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9010, dev_loss=0.3339\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9017, dev_loss=0.3370\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9031, dev_loss=0.3288\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9042, dev_loss=0.3376\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9029, dev_loss=0.3377\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9002, dev_loss=0.3374\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9002, dev_loss=0.3326\n",
      "train_acc = 0.9141\n",
      "dev_acc = 0.9011, dev_loss=0.3353\n",
      "1/10\n",
      "train_acc = 0.8984\n",
      "dev_acc = 0.9036, dev_loss=0.3265\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9015, dev_loss=0.3397\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9022, dev_loss=0.3371\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.8995, dev_loss=0.3466\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9037, dev_loss=0.3385\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9045, dev_loss=0.3402\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9013, dev_loss=0.3509\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9015, dev_loss=0.3452\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9024, dev_loss=0.3408\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9041, dev_loss=0.3404\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9063, dev_loss=0.3365\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9022, dev_loss=0.3504\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9054, dev_loss=0.3314\n",
      "train_acc = 0.9141\n",
      "dev_acc = 0.9008, dev_loss=0.3446\n",
      "2/10\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9009, dev_loss=0.3419\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9047, dev_loss=0.3381\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9003, dev_loss=0.3555\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9051, dev_loss=0.3461\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9015, dev_loss=0.3415\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9050, dev_loss=0.3397\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9047, dev_loss=0.3459\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9024, dev_loss=0.3508\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9035, dev_loss=0.3439\n",
      "train_acc = 0.9062\n",
      "dev_acc = 0.9029, dev_loss=0.3610\n",
      "train_acc = 0.9062\n",
      "dev_acc = 0.9019, dev_loss=0.3539\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9037, dev_loss=0.3512\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9033, dev_loss=0.3499\n",
      "train_acc = 0.9141\n",
      "dev_acc = 0.9010, dev_loss=0.3490\n",
      "3/10\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9016, dev_loss=0.3515\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9050, dev_loss=0.3535\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9031, dev_loss=0.3525\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9020, dev_loss=0.3594\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9016, dev_loss=0.3535\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9036, dev_loss=0.3525\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9047, dev_loss=0.3584\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9004, dev_loss=0.3642\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9039, dev_loss=0.3598\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9033, dev_loss=0.3581\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9026, dev_loss=0.3644\n",
      "train_acc = 0.9062\n",
      "dev_acc = 0.9009, dev_loss=0.3722\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9044, dev_loss=0.3624\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9028, dev_loss=0.3591\n",
      "4/10\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9035, dev_loss=0.3610\n",
      "train_acc = 0.9844\n",
      "dev_acc = 0.9064, dev_loss=0.3667\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9031, dev_loss=0.3673\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9022, dev_loss=0.3797\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9024, dev_loss=0.3720\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9002, dev_loss=0.3849\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9058, dev_loss=0.3758\n",
      "train_acc = 0.9844\n",
      "dev_acc = 0.9031, dev_loss=0.3849\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9039, dev_loss=0.3727\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9038, dev_loss=0.3744\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9027, dev_loss=0.3704\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9022, dev_loss=0.3862\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9032, dev_loss=0.3767\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9041, dev_loss=0.3702\n",
      "5/10\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9023, dev_loss=0.3742\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9054, dev_loss=0.3706\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9045, dev_loss=0.3727\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9033, dev_loss=0.3833\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9045, dev_loss=0.3806\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9049, dev_loss=0.3787\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9037, dev_loss=0.3891\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9012, dev_loss=0.3954\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9014, dev_loss=0.3931\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9024, dev_loss=0.3814\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9068, dev_loss=0.3729\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9021, dev_loss=0.3937\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9060, dev_loss=0.3854\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9040, dev_loss=0.3889\n",
      "6/10\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9031, dev_loss=0.3867\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9000, dev_loss=0.3994\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9049, dev_loss=0.3962\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9016, dev_loss=0.4055\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9031, dev_loss=0.3921\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9023, dev_loss=0.3986\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9038, dev_loss=0.3960\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9024, dev_loss=0.3990\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9008, dev_loss=0.4028\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9069, dev_loss=0.3986\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9033, dev_loss=0.3999\n",
      "train_acc = 0.9297\n",
      "dev_acc = 0.9064, dev_loss=0.3976\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9050, dev_loss=0.3990\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9040, dev_loss=0.3972\n",
      "7/10\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9054, dev_loss=0.3957\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9045, dev_loss=0.3992\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9070, dev_loss=0.3979\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9061, dev_loss=0.4040\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9021, dev_loss=0.4065\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9056, dev_loss=0.3996\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9065, dev_loss=0.4051\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9058, dev_loss=0.4081\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9045, dev_loss=0.4087\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9016, dev_loss=0.4079\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9045, dev_loss=0.4115\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9044, dev_loss=0.4051\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9031, dev_loss=0.4163\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9021, dev_loss=0.4239\n",
      "8/10\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9033, dev_loss=0.4174\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9030, dev_loss=0.4237\n",
      "train_acc = 0.9844\n",
      "dev_acc = 0.9041, dev_loss=0.4140\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9014, dev_loss=0.4291\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9019, dev_loss=0.4222\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9003, dev_loss=0.4276\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9003, dev_loss=0.4290\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9007, dev_loss=0.4362\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.8999, dev_loss=0.4440\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9015, dev_loss=0.4293\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9009, dev_loss=0.4303\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9032, dev_loss=0.4244\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.8989, dev_loss=0.4410\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.8999, dev_loss=0.4418\n",
      "9/10\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9023, dev_loss=0.4357\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.9025, dev_loss=0.4313\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9019, dev_loss=0.4316\n",
      "train_acc = 0.9453\n",
      "dev_acc = 0.9050, dev_loss=0.4293\n",
      "train_acc = 0.9219\n",
      "dev_acc = 0.9049, dev_loss=0.4322\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9039, dev_loss=0.4251\n",
      "train_acc = 0.9766\n",
      "dev_acc = 0.9024, dev_loss=0.4405\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9038, dev_loss=0.4427\n",
      "train_acc = 0.9688\n",
      "dev_acc = 0.8988, dev_loss=0.4621\n",
      "train_acc = 0.9844\n",
      "dev_acc = 0.9032, dev_loss=0.4389\n",
      "train_acc = 0.9375\n",
      "dev_acc = 0.9015, dev_loss=0.4306\n",
      "train_acc = 0.9531\n",
      "dev_acc = 0.9001, dev_loss=0.4370\n",
      "train_acc = 1.0000\n",
      "dev_acc = 0.9032, dev_loss=0.4373\n",
      "train_acc = 0.9609\n",
      "dev_acc = 0.9028, dev_loss=0.4368\n"
     ]
    }
   ],
   "source": [
    "# import pdb\n",
    "# pdb.set_trace()\n",
    "train(model_txtcnn, train_dl, dev_dl,10, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db2356c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   33415 KB |   76636 KB |    2083 GB |    2083 GB |\n",
      "|       from large pool |   22323 KB |   59340 KB |    1865 GB |    1865 GB |\n",
      "|       from small pool |   11092 KB |   22387 KB |     218 GB |     218 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   33415 KB |   76636 KB |    2083 GB |    2083 GB |\n",
      "|       from large pool |   22323 KB |   59340 KB |    1865 GB |    1865 GB |\n",
      "|       from small pool |   11092 KB |   22387 KB |     218 GB |     218 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   57344 KB |  108544 KB |  108544 KB |   51200 KB |\n",
      "|       from large pool |   40960 KB |   81920 KB |   81920 KB |   40960 KB |\n",
      "|       from small pool |   16384 KB |   26624 KB |   26624 KB |   10240 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |   23928 KB |   44639 KB |    3202 GB |    3202 GB |\n",
      "|       from large pool |   18637 KB |   35669 KB |    2959 GB |    2959 GB |\n",
      "|       from small pool |    5291 KB |    9010 KB |     242 GB |     242 GB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |      72    |     116    |    2093 K  |    2093 K  |\n",
      "|       from large pool |       6    |      16    |     522 K  |     522 K  |\n",
      "|       from small pool |      66    |     106    |    1570 K  |    1570 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |      72    |     116    |    2093 K  |    2093 K  |\n",
      "|       from large pool |       6    |      16    |     522 K  |     522 K  |\n",
      "|       from small pool |      66    |     106    |    1570 K  |    1570 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      10    |      17    |      17    |       7    |\n",
      "|       from large pool |       2    |       4    |       4    |       2    |\n",
      "|       from small pool |       8    |      13    |      13    |       5    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      17    |      25    |     805 K  |     805 K  |\n",
      "|       from large pool |       3    |       6    |     352 K  |     352 K  |\n",
      "|       from small pool |      14    |      22    |     453 K  |     453 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

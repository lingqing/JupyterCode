{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d288ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e299023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open(('data/mnist.pkl.gz'), 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74fcb973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(x_train[0].reshape(28, 28), cmap='gray')\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c616b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x_train, y_train, x_valid, y_valid = map(\n",
    "       torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bf5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Mnist_NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128)\n",
    "        self.linear2 = nn.Linear(128, 256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6972df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist_NN(\n",
      "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Mnist_NN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1b526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[ 0.0272, -0.0004,  0.0230,  ..., -0.0121, -0.0119,  0.0336],\n",
      "        [ 0.0173,  0.0136,  0.0253,  ..., -0.0081, -0.0155,  0.0020],\n",
      "        [ 0.0357,  0.0207,  0.0033,  ..., -0.0240, -0.0191,  0.0012],\n",
      "        ...,\n",
      "        [-0.0236, -0.0031, -0.0236,  ...,  0.0049,  0.0196, -0.0140],\n",
      "        [ 0.0206, -0.0174, -0.0012,  ..., -0.0222,  0.0012, -0.0213],\n",
      "        [-0.0186,  0.0042, -0.0320,  ..., -0.0299,  0.0313, -0.0162]],\n",
      "       requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([ 0.0010,  0.0296, -0.0322,  0.0334, -0.0140,  0.0320, -0.0241,  0.0056,\n",
      "         0.0320, -0.0082,  0.0220,  0.0279,  0.0114, -0.0180, -0.0290, -0.0048,\n",
      "         0.0163, -0.0149,  0.0157,  0.0176, -0.0142,  0.0280,  0.0013, -0.0127,\n",
      "        -0.0287, -0.0174,  0.0168, -0.0132, -0.0226, -0.0025, -0.0185,  0.0161,\n",
      "        -0.0338, -0.0106,  0.0117, -0.0126, -0.0104,  0.0260,  0.0282,  0.0347,\n",
      "        -0.0274, -0.0002,  0.0122, -0.0077, -0.0151, -0.0060,  0.0272,  0.0051,\n",
      "         0.0253, -0.0126,  0.0351,  0.0210, -0.0141,  0.0032, -0.0034, -0.0224,\n",
      "         0.0183, -0.0274,  0.0008,  0.0264, -0.0113,  0.0248, -0.0115, -0.0165,\n",
      "        -0.0015, -0.0072, -0.0165, -0.0237, -0.0150,  0.0296,  0.0118, -0.0072,\n",
      "         0.0074,  0.0030, -0.0107, -0.0077, -0.0340,  0.0182, -0.0198,  0.0080,\n",
      "         0.0030,  0.0320,  0.0330,  0.0253, -0.0188, -0.0268,  0.0050,  0.0005,\n",
      "        -0.0319, -0.0151, -0.0229, -0.0289, -0.0135, -0.0146, -0.0289, -0.0199,\n",
      "         0.0007, -0.0139,  0.0282,  0.0136, -0.0187,  0.0310, -0.0031, -0.0060,\n",
      "         0.0135,  0.0043, -0.0106, -0.0202, -0.0071, -0.0296, -0.0233, -0.0351,\n",
      "         0.0130, -0.0182,  0.0006, -0.0353,  0.0275,  0.0159, -0.0272, -0.0031,\n",
      "        -0.0152,  0.0213, -0.0297,  0.0079, -0.0232, -0.0250,  0.0286, -0.0193],\n",
      "       requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[-0.0691,  0.0322,  0.0863,  ..., -0.0685,  0.0552, -0.0542],\n",
      "        [-0.0833,  0.0732, -0.0570,  ...,  0.0563,  0.0483,  0.0254],\n",
      "        [-0.0250,  0.0409, -0.0146,  ..., -0.0194, -0.0884, -0.0745],\n",
      "        ...,\n",
      "        [ 0.0572, -0.0073,  0.0084,  ...,  0.0311, -0.0818, -0.0149],\n",
      "        [-0.0004, -0.0249, -0.0626,  ...,  0.0844, -0.0395, -0.0659],\n",
      "        [ 0.0429,  0.0018,  0.0019,  ...,  0.0136,  0.0784, -0.0271]],\n",
      "       requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([ 0.0776, -0.0472, -0.0850, -0.0169, -0.0870,  0.0544,  0.0875,  0.0103,\n",
      "        -0.0591, -0.0450, -0.0647, -0.0446, -0.0403,  0.0548, -0.0677,  0.0355,\n",
      "         0.0842,  0.0240,  0.0453, -0.0732, -0.0778, -0.0438,  0.0243, -0.0631,\n",
      "         0.0475, -0.0707, -0.0743,  0.0137, -0.0692,  0.0602,  0.0436, -0.0621,\n",
      "        -0.0313,  0.0594, -0.0310,  0.0727, -0.0840, -0.0768, -0.0204, -0.0500,\n",
      "        -0.0749, -0.0129,  0.0109, -0.0713,  0.0687, -0.0516, -0.0803,  0.0883,\n",
      "        -0.0141, -0.0071, -0.0001,  0.0540, -0.0374,  0.0820, -0.0688,  0.0074,\n",
      "         0.0108,  0.0867, -0.0316, -0.0247,  0.0547, -0.0637,  0.0383,  0.0755,\n",
      "         0.0076, -0.0027, -0.0341,  0.0282, -0.0682, -0.0866,  0.0081, -0.0748,\n",
      "        -0.0294,  0.0671, -0.0252, -0.0372,  0.0352, -0.0041, -0.0429,  0.0574,\n",
      "         0.0381, -0.0179,  0.0701, -0.0356, -0.0574, -0.0779, -0.0734,  0.0877,\n",
      "         0.0290,  0.0743, -0.0059,  0.0646,  0.0301,  0.0554, -0.0604, -0.0564,\n",
      "         0.0067, -0.0204,  0.0735,  0.0707, -0.0528,  0.0394,  0.0158, -0.0807,\n",
      "        -0.0867, -0.0704, -0.0873,  0.0882,  0.0293, -0.0422,  0.0651,  0.0341,\n",
      "         0.0357, -0.0474, -0.0041,  0.0056, -0.0739, -0.0047, -0.0642, -0.0795,\n",
      "         0.0825, -0.0305,  0.0037,  0.0279,  0.0760,  0.0495, -0.0342, -0.0729,\n",
      "         0.0158, -0.0443, -0.0127, -0.0536,  0.0573,  0.0340,  0.0494, -0.0418,\n",
      "         0.0440,  0.0590, -0.0385, -0.0060,  0.0250,  0.0253,  0.0106,  0.0492,\n",
      "        -0.0297,  0.0577,  0.0020, -0.0826, -0.0370,  0.0862,  0.0769, -0.0745,\n",
      "        -0.0789, -0.0333, -0.0410,  0.0098,  0.0417, -0.0348,  0.0057, -0.0833,\n",
      "         0.0515,  0.0850, -0.0424,  0.0129, -0.0247,  0.0617, -0.0449,  0.0003,\n",
      "        -0.0876,  0.0839, -0.0283,  0.0124, -0.0537, -0.0094, -0.0422,  0.0686,\n",
      "        -0.0071, -0.0106, -0.0238, -0.0362, -0.0177, -0.0618,  0.0410,  0.0728,\n",
      "         0.0378,  0.0227,  0.0093, -0.0547,  0.0552,  0.0373, -0.0090,  0.0411,\n",
      "         0.0221, -0.0857, -0.0649,  0.0351,  0.0583,  0.0768, -0.0868, -0.0809,\n",
      "         0.0654, -0.0443, -0.0632,  0.0631,  0.0542,  0.0030,  0.0031, -0.0581,\n",
      "        -0.0053, -0.0218, -0.0447,  0.0289,  0.0201,  0.0750, -0.0239,  0.0494,\n",
      "         0.0402, -0.0351, -0.0389, -0.0296, -0.0874,  0.0254,  0.0514, -0.0366,\n",
      "        -0.0741,  0.0232,  0.0062, -0.0241,  0.0202, -0.0518,  0.0009, -0.0796,\n",
      "        -0.0210, -0.0344,  0.0312, -0.0013, -0.0712,  0.0092,  0.0589,  0.0633,\n",
      "        -0.0774,  0.0282, -0.0754,  0.0576, -0.0092, -0.0483, -0.0864, -0.0761,\n",
      "        -0.0627, -0.0424,  0.0767, -0.0345,  0.0800,  0.0447,  0.0870, -0.0785],\n",
      "       requires_grad=True)\n",
      "out.weight Parameter containing:\n",
      "tensor([[ 0.0496,  0.0016,  0.0050,  ...,  0.0191,  0.0069,  0.0153],\n",
      "        [ 0.0061, -0.0167, -0.0161,  ..., -0.0242, -0.0346,  0.0623],\n",
      "        [-0.0383,  0.0412,  0.0350,  ...,  0.0075, -0.0475,  0.0387],\n",
      "        ...,\n",
      "        [-0.0596,  0.0581, -0.0569,  ...,  0.0545,  0.0276, -0.0078],\n",
      "        [ 0.0265, -0.0533, -0.0322,  ..., -0.0328,  0.0162, -0.0601],\n",
      "        [-0.0233,  0.0618, -0.0608,  ..., -0.0579, -0.0377,  0.0147]],\n",
      "       requires_grad=True)\n",
      "out.bias Parameter containing:\n",
      "tensor([ 0.0164, -0.0277,  0.0195, -0.0274,  0.0592, -0.0245, -0.0586, -0.0518,\n",
      "        -0.0284, -0.0466], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in net.named_parameters():\n",
    "    print(name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958f5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "bs = 64\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "trail_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f23f8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs*2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0c422ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab02dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_NN()\n",
    "    return model, torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c33509bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(steps, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for step in range(steps):\n",
    "#         model.train()  # ??\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "            \n",
    "#         model.eval()\n",
    "#         print(valid_dl)\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[ loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "            \n",
    "        val_loss = np.sum(np.multiply(losses, nums))/np.sum(nums)\n",
    "        \n",
    "        print('cur step: '+ str(step), 'valid loss = ' + str(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1da2608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8940ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cur step: 0 valid loss = 2.146269161224365\n",
      "cur step: 1 valid loss = 1.9187297424316405\n",
      "cur step: 2 valid loss = 1.5988143125534058\n",
      "cur step: 3 valid loss = 1.2763635175704957\n",
      "cur step: 4 valid loss = 1.0291409896850585\n",
      "cur step: 5 valid loss = 0.8570390712738037\n",
      "cur step: 6 valid loss = 0.7386548881530761\n",
      "cur step: 7 valid loss = 0.6558200610160828\n",
      "cur step: 8 valid loss = 0.5956096018791198\n",
      "cur step: 9 valid loss = 0.5505643909454345\n",
      "cur step: 10 valid loss = 0.5151873041629791\n",
      "cur step: 11 valid loss = 0.4876185863018036\n",
      "cur step: 12 valid loss = 0.46480129671096804\n",
      "cur step: 13 valid loss = 0.4459637619495392\n",
      "cur step: 14 valid loss = 0.4302060249328613\n",
      "cur step: 15 valid loss = 0.4167512948513031\n",
      "cur step: 16 valid loss = 0.40546345632076264\n",
      "cur step: 17 valid loss = 0.39551858854293825\n",
      "cur step: 18 valid loss = 0.3868999848842621\n",
      "cur step: 19 valid loss = 0.3792587815761566\n",
      "cur step: 20 valid loss = 0.3726405105113983\n",
      "cur step: 21 valid loss = 0.36669742047786713\n",
      "cur step: 22 valid loss = 0.3612789717912674\n",
      "cur step: 23 valid loss = 0.35633972737789155\n",
      "cur step: 24 valid loss = 0.35190103707313536\n"
     ]
    }
   ],
   "source": [
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(25, model, loss_func, opt, trail_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "97c1860a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "precit =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3567391/888816149.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ans = torch.argmax(model(torch.tensor(x_valid[k])))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for i in range(10):\n",
    "import random\n",
    "k = random.randint(0, x_valid.shape[0])\n",
    "pyplot.imshow(x_valid[k].numpy().reshape(28,28),cmap='gray')\n",
    "print(y_valid[k].numpy())    \n",
    "ans = torch.argmax(model(torch.tensor(x_valid[k])))\n",
    "print('precit = ', ans.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
